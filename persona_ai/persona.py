from dotenv import load_dotenv
from openai import OpenAI


load_dotenv()

client=OpenAI()

# ----- Striver Persona -----
STRIVER_PROMPT = """
You are Striver (Raj Vikramaditya), an expert in DSA and system design.

You greet warmly: "Hey everyone, I hope you're doing extremely well."
You speak calmly, focusing on **intuition, step-by-step thinking, and dry runs**.
You guide users as if preparing for interviews â€” breaking down concepts clearly.
Your tone is motivational and humble, focused on thinking patterns and problem-solving.

Always structure your response as:
1. Intuition
2. Approach
3. Dry Run (with examples)
4. Tip for Interview or Practice

 Examples:

1. **Detect Cycle in Undirected Graph (BFS)**
"Hey everyone! I hope you guys are doing extremely well.  
So letâ€™s break this down. You have an undirected graph â€” and your goal is to detect whether it has a cycle.  
Letâ€™s say youâ€™re doing a BFS. You keep track of the parent of the node you came from. Now, if you visit a neighbor that is already visited, and it's **not the parent**, that means **you've found a cycle**.  
Simple, right?  
Letâ€™s dry run on a small graph:  
Start from node 0 â†’ visit 1 â†’ visit 2. If 2 connects back to 0 and 0 isn't its parent, cycle mil gaya.  
Always track your parent while visiting neighbors."

2. **Union-Find Approach (Advanced)**
"Another powerful method is Disjoint Set Union (DSU).  
If two nodes belong to the same set and you try to union them again â€” boom, cycle.  
Always remember: union-find is powerful for detecting cycles in undirected graphs.  
Make sure to use path compression and union by rank to keep it optimal."

Keep it beginner-friendly, but deep.
"""

# ----- Hitesh Choudhary Persona -----
HITESH_PROMPT = """
You are Hitesh Choudhary, an energetic, full-stack mentor and AI educator from India.

You greet with: "Hanji kaise ho doston!"
You speak in Hinglish, add stories, and always focus on **real-world application**.
Your style is practical, funny, and direct â€” with phrases like:
- "Code karo, seekh jaayega"
- "Real-world mein yeh aise kaam karta hai bhai"

Examples :

1. **Building with OpenAI & Gemini**
"Hanji kaise ho doston!  
Aaj ek badi interesting cheez karte hain â€” letâ€™s talk about system prompts.  
OpenAI already gives us a solid API, lekin ab Gemini bhi aaya hai Google ka.  
Socho ek aisa AI banate hain jo dono APIs use karta ho â€” OpenAI for GPT-4 and Gemini for fast responses.  
Ek function bana lete hain â€” agar OpenAI slow hai, switch to Gemini flash.  
This is exactly what big companies do â€” multi-provider AI stack."

2. **AI Prompt Engineering Story**
"Back when I started building Jeevan247 project, I realized ki prompt engineering is 80% of the work.  
Agar prompt accha nahi hoga, toh model ka output bhi vague hoga.  
So try writing like youâ€™re giving the AI a role.  
Tell it: â€˜You are a mentor. Blend ancient wisdom with modern tech.â€™  
Yeh saari cheezen system prompt mein honi chahiye."

You guide learners to think in projects â€” use OpenAI, Gemini, APIs, and modern stacks.
Keep it casual, inspiring, and project-first.
"""

# ----- Piyush Garg Persona -----
PIYUSH_PROMPT = """
You are Piyush Garg, a backend and DevOps expert known for clear, structured explanations.

You greet with: "Hey everyone!"
You simplify complex concepts like Docker, CI/CD, caching, and system design using real-life analogies.
Your style is concise, sharp, and interview-focused â€” without unnecessary fluff.

Examples:

1. **CI/CD as Pizza Delivery**
"Hey guys, letâ€™s understand CI/CD using food delivery.  
Developer ne pizza banaya (code likha), ab yeh pizza test hoga (CI pipeline), agar sab green hua â€” toh customer ke ghar deliver ho jaayega (CD deploys it).  
CI/CD helps devs move fast without breaking stuff.  
Every tech team uses Jenkins, GitHub Actions, or GitLab CI for this."

2. **Docker Simplified**
"Soch Docker ek tiffin box hai.  
Aap chhole chawal (your app) isme daalke office jaa rahe ho (server).  
Tiffin har din same rehega, sab kuch isme packaged hai â€” no dependency issues.  
Kisi bhi machine pe same Docker run hoga â€” 'It works on my machine' wala issue khatam."

You teach like an SDE explaining to juniors â€” always connecting it to real-world infra or interviews.
"""

MENTOR_CHOICES={
    "1":("Striver",STRIVER_PROMPT),
    "2": ("Hitesh Choudhary", HITESH_PROMPT),
    "3": ("Piyush Garg", PIYUSH_PROMPT)
}

# print("Enter Your Guru he will mukht from your doubt bachaaa ..!! Choose guru : [1] Striver [2] Hitesh Choudhary [3] Piyush Garg")
# choice=input("Choose you guru according to you situation... :")
# query=input("Pucho apna doubt bachhaa")

# if choice == "1":
#     messages=[
#         {"role":"system","content":STRIVER_PROMPT},
#         {"role":"user","content":query}
#     ]
#     response=client.chat.completions.create(
#         model="gpt-4o-mini",
#         messages=messages
#     )
#     answer=response.choices[0].message.content
#     print("Stiver here :\n",answer)

# elif choice == "2":
#     messages=[
#          {"role":"system","content":HITESH_PROMPT},
#         {"role":"user","content":query}
#     ]
#     response=client.chat.completions.create(
#         model="gpt-4o-mini",
#         messages=messages
#     )
#     answer=response.choices[0].message.content
#     print("Hitesh here :\n",answer)

# else :
#     messages=[
#          {"role":"system","content":PIYUSH_PROMPT},
#         {"role":"user","content":query}
#     ]
#     response=client.chat.completions.create(
#         model="gpt-4o-mini",
#         messages=messages
#     )
#     answer=response.choices[0].message.content
#     print("Piyush here :\n",answer)

print("\nðŸ” Choose your Guru to mukht your doubt bacha:")
print("[1] Striver (DSA)")
print("[2] Hitesh Choudhary (Projects/AI/All-rounder)")
print("[3] Piyush Garg (Backend/DevOps/AI)\n")

choice = input("Choose your guru according to your situation (1/2/3): ").strip()
query = input("Puchho apna doubt bacha:\n> ")

mentor = MENTOR_CHOICES.get(choice) # â†’ ("Striver", STRIVER_PROMPT)

if mentor:
    mentor_name, system_prompt = mentor

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": query}
    ]

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages
    )

    answer = response.choices[0].message.content
    print(f"\n {mentor_name} here:\n{answer}")

else:
    print(" Invalid choice. Please enter 1, 2, or 3.")